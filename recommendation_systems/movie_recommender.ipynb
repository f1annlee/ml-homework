{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('movies_metadata.csv')\n",
    "ratings=pd.read_csv('ratings_small.csv')\n",
    "links=pd.read_csv('links_small.csv')\n",
    "keywords=pd.read_csv('keywords.csv')\n",
    "credit=pd.read_csv('credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dcc8b73be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl81dWd//HXJwlJCFsgCRgJIUAA\n2SqbLO5IQVxGlGrFvS0d3OgydtrR6eivdToL02ltO1Irig5SFaxLpS7gAtYdCLIjSNgjOwlhDWT5\n/P64BxszwVwg5Cbh/Xw8vo98v+d7vifncC/3fb9rzN0RERGJi3UHRESkflAgiIgIoEAQEZFAgSAi\nIoACQUREAgWCiIgACgQREQkUCCIiAigQREQkSIh1B45Henq65+TkxLobIiINysKFC3e5e0ZN9RpU\nIOTk5JCXlxfrboiINChmtjGaejpkJCIigAJBREQCBYKIiAAKBBERCRQIIiICRBkIZjbKzFabWb6Z\n3VvN+iQzmxHWzzOznFA+yMwWh2mJmV0TbZsiIlK3agwEM4sHJgGXAT2BG8ysZ5Vq44Aid88FHgIm\nhvLlwEB37wuMAh41s4Qo2xQRkToUzR7CICDf3de5+xFgOjC6Sp3RwNQw/zww3MzM3Q+6e1koTwaO\n/r3OaNoUEZE6FE0gtAc2V1ouCGXV1gkBUAykAZjZYDNbASwD7gjro2lTRETqUDR3Kls1ZR5tHXef\nB/Qysx7AVDN7Pco2Iw2bjQfGA2RnZ0fR3dPbM/M2fWn5xsEn/m9Wua2a2qnN33sy/ZDGT++HUyea\nPYQCoEOl5Sxgy7HqmFkC0AoorFzB3T8FDgC9o2zz6HaT3X2guw/MyKjxURwiInKCogmEBUBXM+tk\nZonAWGBmlTozgdvC/LXAHHf3sE0CgJl1BLoDG6JsU0RE6lCNh4zcvczMJgCzgXjgCXdfYWYPAnnu\nPhOYAkwzs3wiewZjw+bnA/eaWSlQAdzl7rsAqmuzlscmIiLHIaqnnbr7a8BrVcoeqDRfAlxXzXbT\ngGnRtikiIrGjO5VFRARQIIiISKBAEBERQIEgIiKBAkFERAAFgoiIBAoEEREBFAgiIhIoEEREBFAg\niIhIoEAQERFAgSAiIoECQUREAAWCiIgECgQREQEUCCIiEigQREQEUCCIiEigQBAREUCBICIigQJB\nREQABYKIiAQKBBERARQIIiISKBBERARQIIiISBBVIJjZKDNbbWb5ZnZvNeuTzGxGWD/PzHJC+Qgz\nW2hmy8LPSypt805oc3GY2tbWoERE5Pgl1FTBzOKBScAIoABYYGYz3X1lpWrjgCJ3zzWzscBE4Hpg\nF/B37r7FzHoDs4H2lba7yd3zamksIiJyEqLZQxgE5Lv7Onc/AkwHRlepMxqYGuafB4abmbn7Inff\nEspXAMlmllQbHRcRkdoVTSC0BzZXWi7gy9/yv1TH3cuAYiCtSp1vAIvc/XClsifD4aL7zcyq++Vm\nNt7M8swsb+fOnVF0V0RETkQ0gVDdB7UfTx0z60XkMNLtldbf5O59gAvCdEt1v9zdJ7v7QHcfmJGR\nEUV3RUTkREQTCAVAh0rLWcCWY9UxswSgFVAYlrOAl4Bb3X3t0Q3c/fPwcx/wDJFDUyIiEiPRBMIC\noKuZdTKzRGAsMLNKnZnAbWH+WmCOu7uZpQKvAve5+wdHK5tZgpmlh/kmwJXA8pMbioiInIwaAyGc\nE5hA5AqhT4Hn3H2FmT1oZleFalOANDPLB+4Bjl6aOgHIBe6vcnlpEjDbzJYCi4HPgcdqc2AiInJ8\narzsFMDdXwNeq1L2QKX5EuC6arb7BfCLYzQ7IPpuiojIqaY7lUVEBFAgiIhIoEAQERFAgSAiIoEC\nQUREAAWCiIgECgQREQEUCCIiEigQREQEUCCIiEigQBAREUCBICIigQJBREQABYKIiAQKBBERARQI\nIiISKBBERARQIIiISKBAEBERQIEgIiKBAkFERAAFgoiIBAoEEREBFAgiIhIoEEREBIgyEMxslJmt\nNrN8M7u3mvVJZjYjrJ9nZjmhfISZLTSzZeHnJZW2GRDK883sd2ZmtTUoERE5fjUGgpnFA5OAy4Ce\nwA1m1rNKtXFAkbvnAg8BE0P5LuDv3L0PcBswrdI2jwDjga5hGnUS4xARkZMUzR7CICDf3de5+xFg\nOjC6Sp3RwNQw/zww3MzM3Re5+5ZQvgJIDnsTmUBLd//I3R14Crj6pEcjIiInLJpAaA9srrRcEMqq\nrePuZUAxkFalzjeARe5+ONQvqKFNERGpQwlR1Knu2L4fTx0z60XkMNLI42jz6LbjiRxaIjs7u6a+\niojICYpmD6EA6FBpOQvYcqw6ZpYAtAIKw3IW8BJwq7uvrVQ/q4Y2AXD3ye4+0N0HZmRkRNFdERE5\nEdEEwgKgq5l1MrNEYCwws0qdmUROGgNcC8xxdzezVOBV4D53/+BoZXffCuwzsyHh6qJbgZdPciwi\nInISagyEcE5gAjAb+BR4zt1XmNmDZnZVqDYFSDOzfOAe4OilqROAXOB+M1scprZh3Z3A40A+sBZ4\nvbYGJSIixy+acwi4+2vAa1XKHqg0XwJcV812vwB+cYw284Dex9NZERE5dXSnsoiIAAoEEREJFAgi\nIgIoEEREJFAgiIgIoEAQEZFAgSAiIoACQUREAgWCiIgACgQREQkUCCIiAigQREQkUCCIiAigQBAR\nkUCBICIigAJBREQCBYKIiAAKBBERCRQIIiICKBBERCRQIIiICKBAEBGRQIEgIiKAAkFERAIFgoiI\nAAoEEREJogoEMxtlZqvNLN/M7q1mfZKZzQjr55lZTihPM7O5ZrbfzB6uss07oc3FYWpbGwMSEZET\nk1BTBTOLByYBI4ACYIGZzXT3lZWqjQOK3D3XzMYCE4HrgRLgfqB3mKq6yd3zTnIMIiJSC6LZQxgE\n5Lv7Onc/AkwHRlepMxqYGuafB4abmbn7AXd/n0gwiIhIPRZNILQHNldaLghl1dZx9zKgGEiLou0n\nw+Gi+83MqqtgZuPNLM/M8nbu3BlFkyIiciKiCYTqPqj9BOpUdZO79wEuCNMt1VVy98nuPtDdB2Zk\nZNTYWREROTHRBEIB0KHSchaw5Vh1zCwBaAUUflWj7v55+LkPeIbIoSkREYmRaAJhAdDVzDqZWSIw\nFphZpc5M4LYwfy0wx92PuYdgZglmlh7mmwBXAsuPt/MiIlJ7arzKyN3LzGwCMBuIB55w9xVm9iCQ\n5+4zgSnANDPLJ7JnMPbo9ma2AWgJJJrZ1cBIYCMwO4RBPPAW8FitjkxERI5LjYEA4O6vAa9VKXug\n0nwJcN0xts05RrMDouuiiIjUBd2pLCIigAJBREQCBYKIiAAKBBERCRQIIiICKBBERCRQIIiICKBA\nEBGRQIEgIiKAAkFERAIFgoiIAAoEEREJFAgiIgIoEEREJFAgiIgIoEAQEZFAgSAiIoACQUREAgWC\niIgACgQREQkUCCIiAigQREQkUCCIiAigQBARkUCBICIiQJSBYGajzGy1meWb2b3VrE8ysxlh/Twz\nywnlaWY218z2m9nDVbYZYGbLwja/MzOrjQGJiMiJqTEQzCwemARcBvQEbjCznlWqjQOK3D0XeAiY\nGMpLgPuBf6ym6UeA8UDXMI06kQGIiEjtiGYPYRCQ7+7r3P0IMB0YXaXOaGBqmH8eGG5m5u4H3P19\nIsHwBTPLBFq6+0fu7sBTwNUnMxARETk50QRCe2BzpeWCUFZtHXcvA4qBtBraLKihTRERqUPRBEJ1\nx/b9BOqcUH0zG29meWaWt3Pnzq9oUkRETkY0gVAAdKi0nAVsOVYdM0sAWgGFNbSZVUObALj7ZHcf\n6O4DMzIyouiuiIiciGgCYQHQ1cw6mVkiMBaYWaXOTOC2MH8tMCecG6iWu28F9pnZkHB10a3Ay8fd\nexERqTUJNVVw9zIzmwDMBuKBJ9x9hZk9COS5+0xgCjDNzPKJ7BmMPbq9mW0AWgKJZnY1MNLdVwJ3\nAv8LNAVeD5OIiMRIjYEA4O6vAa9VKXug0nwJcN0xts05Rnke0DvajoqIyKmlO5VFRARQIIiISKBA\nEBERQIEgIiKBAkFERAAFgoiIBAoEEREBFAgiIhIoEEREBFAgiIhIoEAQERFAgSAiIoECQUREAAWC\niIgECgQREQEUCCIiEigQREQEUCCIiEigQBAREUCBICIiQUKsOyD1X4U763cdYMOuAxQfKmVfSSlm\nRnKTeFo1bUJ2mxSOlFWQmKDvFyINmQJB/o/yCmfe+t3MXrGNtTv3s624hLIK/8ptDGjXMpnstBRy\nM5pz8EgZKYl6e4k0JPofK1/I37Gf6fM3MXPJFnbsO0ycQYfWKQztksZVZ59J54xmtE5JpEVyExyn\n5EgFhQePsHH3AV5evIXNhQdZsnkP89cX8uKiAoZ1b8vYQdlckJtOXJzFengiUgMFgjB/fSGP/nUt\nb6/aQZN4Y1j3tlzdrz3bi0tIahIPwHUDO1S7bXZaCn07pHLgcDkQ2bvYuPsAR8oreHXpVl5fvo2O\naSmMO78T3xzYgeTQnojUPwqE09inW/cycdYq3lm9k7Rmifzw6125ZUhH0ponAfDMvE3H3WZ8nNE5\nozk3Ds7mp1f0YNbybUz9cAMPvLyCSXPzueviXG4cnE2TeJ1vEKlvFAinoeJDpfxy9iqenreJFkkJ\n3HfZWdx2bk6tf3tPSohndN/2XHX2mXy0dje/eXsN/2/mCp76aAP/ckVPhp3VtlZ/n4icnKi+ppnZ\nKDNbbWb5ZnZvNeuTzGxGWD/PzHIqrbsvlK82s0srlW8ws2VmttjM8mpjMFKz15dt5eu//ivPzNvE\nbUNzePcnw7j9oi6n9FCOmXFubjozxg9hym0DqXD49v8u4PZpeWzfW3LKfq+IHJ8a9xDMLB6YBIwA\nCoAFZjbT3VdWqjYOKHL3XDMbC0wErjeznsBYoBdwJvCWmXVz9/Kw3TB331WL45Fj2FtSys9eXsGL\niz6nd/uWPHHbOfTJalWnfTAzhvdoxwVdM5jy/np+89ZnfP1Xf+X+K3ty3cAszHTiWSSWotlDGATk\nu/s6dz8CTAdGV6kzGpga5p8Hhlvkf/doYLq7H3b39UB+aE/q0CebirjsN+/x8pIt/GB4V16667w6\nD4PKEhPiuPPiLsz+4YX0at+Sn7ywlAnPLqL4UGnM+iQi0QVCe2BzpeWCUFZtHXcvA4qBtBq2deAN\nM1toZuOP9cvNbLyZ5ZlZ3s6dO6Porhzl7jzx/nquf/Qj4uLg+TuG8g8jutWbE7o56c145rtD+Mmo\n7sxavo0rfvceCzcWxbpbIqetaD4ZqtuPr3qX0rHqfNW257l7f+Ay4G4zu7C6X+7uk919oLsPzMjI\niKK7AlBaXsFzeZt58JWVXNStLa9MuIB+2a1j3a3/Iy7OuOviXP50x1AAvvnoR0yam09FDTfCiUjt\niyYQCoDKF6FnAVuOVcfMEoBWQOFXbevuR3/uAF5Ch5Jqzb6SUh5/bx1LCor5x5HdeOzWAbRKaRLr\nbn2l/tmtefX7FzCq9xn8cvZqvjN1AXtLdAhJpC5FEwgLgK5m1snMEomcJJ5Zpc5M4LYwfy0wx909\nlI8NVyF1AroC882smZm1ADCzZsBIYPnJD0e2FZfwyDtr2ba3hBsHZTPhkq4N5mRtq6ZNePiGfvzr\n1b15f80urpn0Aet3HYh1t0ROGzUGQjgnMAGYDXwKPOfuK8zsQTO7KlSbAqSZWT5wD3Bv2HYF8Byw\nEpgF3B2uMGoHvG9mS4D5wKvuPqt2h3b6mbNqO394dy0V7oy/oAu928fuxPGJMjNuGdKRaeMGU3jg\nCFdP+oD8Hftj3S2R00JUN6a5+2vAa1XKHqg0XwJcd4xt/w34typl64Czj7ezcmxPz9vI/X9ezhmt\nkrllSA6tmtbvQ0Q1GdoljZfvPp+/fyqP//1wPZf3yWRo57RYd0ukUasfl5vICXN3/uftNfz0peVc\n3L0t4y/o0uDD4KjstBReuOtcurdrwStLt/KXpVso18lmkVNGgdCAVVQ4D76ykl+9+Rlj+rXn0VsG\nNLq/SdA8KYGbhnTk/Nx0Pl5XyF1PL6SktLzmDUXkuDWuT4/TSGl5BT/60xKe/GAD3zmvE/993dn1\n5v6C2hZnxuV9MrmiTyZvrNzOjY99TOGBI7Hulkij0zg/QRq5Q0fKuX3aQl5a9Dk/vrQ791/Z47T4\newPn5abz+xv7s3zLXq595EM27T4Y6y6JNCoKhAam+GApt0yZx9zVO/i3a3pz97DcBnNZaW24rE8m\nT393MLsPHGHMIx+wrKA41l0SaTQUCA3Ijr0lXD/5I5YWFDPpxv7cNLhjrLsUE+fktOGFO88lKSGe\n6yd/xNzVO2LdJZFGQYHQQGzYdYBv/OFDNhUe5IlvncPlfTJj3aWYym3bnJfuOpdO6c347tQ8Ziw4\n/j/mIyJfpkBoAFZsKebaP3zE/pIynvn7IZzfNT3WXaoX2rZMZsbtQzkvN51/emEZv3pjNZEb5EXk\nRCgQ6rkP1+5i7KMf0yTe+NMdQ+nbITXWXapXmiclMOW2gYw9pwP/Myefe55bwpGyilh3S6RB0p/Q\nrMdeWbqFe2YsoWNaClO/M4gzU5vGukv1UpP4OP5jTB+yWjflv9/4jG3FJfzhlgGN5gY9kbqiPYR6\n6skP1vO9ZxdxdodW/OmOoQqDGpgZEy7pykPXn03exkKufeRDCop0WarI8VAg1DMVFc5/vP4pP//L\nSkb2bMe0cYNJTUmMdbcajGv6ZTH1O4PYtreEa37/Ics/12WpItHSIaN6pKS0nH96YSkvL97CzUOy\n+flVvYk/DW44q23ndknnhTvP5dtPLuCbj37E/9zQj+E92sW6W3KCSkrLWVpQzMKNRazZsY9PNhZR\nfKiUsnJn4qxVJDeJI7VpIhktksht25zuZ7TgnJzWdMloflrdo1MbFAj1xNbiQ9w+bSFLC4r58aXd\nueviLnozn4Ru7Vrw0l3nMm5qHt99Ko8fDu/G9y7JPS3u6G4Mdu47zKwV23hr5XY+WrubI+WRCwXO\naJlMcpM4stukkJgQR8/MlhwqLWfPwVK27S1hxoLNHArPuspokcRF3TK44muZnNclvdE95+tUUCDU\nAws3FnHHHxdy8HAZj906kBE99W22NrRtmcyf7hjKP7+4jIfe+oylBXv49fV9dbK5niqvcOas2sGM\nBZt5Z/UOyiqcnLQUbh3akSGd0+iXnUpa8ySemfe3e05uHJz9pTYqKpyNhQeZt243H67dzewV23h+\nYQGpKU24fmAHbh7SkQ5tUup6aA2GAiHGnsvbzL+8tJzM1GSe/u5gurVrEesuNSrJTeL51TfPpm92\nKg/+ZSVXT/qAP9w8gO5n6N+5vthXUsr0+ZuZ+tEGCooOkdEiiXEXdGJMvyy6tTu+wz5xcUan9GZ0\nSm/G2EHZHC4r5/01u3jhkwIef389j723juE92vGtc3M4t0ua9sKrUCDESElpOb94dSV//HgT5+em\n8/CN/XTy+BQxM24dmkPPzJbc+fQnXD3pA/59TG+u6ZcV666d1ooPlvLkh+t58oMNFB8qZVBOG356\neQ9G9GxHQi09uTcpIZ7hPdoxvEc7tuw5xNPzNvLs/M28uXI73do15+5huVzRJ7PWfl9Dp0CIgfwd\n+5jwzCJWbdvH+As785NLu+sNWQcG5rTh1e+dz4RnFvEPM5bwzuqd/OvVvWmZrENIdWn3/sNMeX89\nT320kf2HyxjRsx0ThuVy9im+6fLM1Kb8+NKz+N4lXXll6VYmv7uWH0xfzK/f/Iw7L+rCmP5Zp/15\nBgVCHSqvcJ78YD2/nL2aZkkJPPntcxjWvW2su3VaadsymWfHD+H3c/P5zdtrWLC+kH8f04eL9Tqc\ncjv2lvDYe+v448ebKCkr5/I+mUwYlkuPzJZ12o/kJvFcOyCLMf3a8+an25k0N597X1zGb99ew+0X\ndmbsoGySm8TXaZ/qCwVCHcnfsY/7XlzGgg1FfL1HW/79mj60bZkc626dluLjjO8N78r5XdP58fNL\n+daTCxjTvz0/vbwHac2TYt29Rqeg6CCT313H9AWbKSuvYHTf9tw9rAu5bWN7Hicuzri01xmM7NmO\nd9fsYtKcfH72l5U8PDef717QmZuHdKR50un1EXl6jTYGDhwu43dz1jDlvfWkJMbzq+vOZkz/9jqZ\nVQ/0y27Nq98/n4fn5PPIO2t5a+V27hnRjZuHdNQhvFqQv2M/j7yzlpcXf44ZjOmXxZ0XdyEnvVms\nu/YlZsZF3TK4qFsG89bt5uG5+fzn66t45J21fOvcHL59Xs5pc35PgXCKlJZXMH3+Jn77dj679h/m\nmwOz+KdRZ+kbaD2TlBDPj0Z2Z3TfM/nZzJX87C8rmfbxRn40sjujep2h+xaOk7uzcGMRU95fz6wV\n20hKiOPWoTn8/YWdyGxV/x+/MrhzGoM7p7Fk8x4mzc3nt2+v4fH31nHz0I6MO78TbVs07r16BUIt\nKykt5/mFBUx+dx2bCg8yqFMbJt86gP7ZrWPdNfkKuW1bMG3cIN5cuZ1fzl7NXU9/Qs/MltxxcRcu\n732G9hhqsP9wGX9e9Dl//Hgjq7bto0VyAndfnMu3z8tpkF+Czu6QyuRbB7Jq215+P3ctj727jife\nX8/IXmdw46BshnZOa5RfFhQItaSg6CDPLdjMM/M3sWv/Ec7ukMrPR/fi4m4ZOjzUQJgZI3udwfAe\n7fjzos+ZNDef7z+7iImpTbl5SEeuHZBFRouG9+F2qlRUOAs3FTFz8RZeWvQ5+w+X0TOzJf85pg9X\n9T2TlMSG//Fy1hkt+d0N/bhnRDemfbyRFz4p4NWlW+mYlsLYc7IZ07897RrRucCG/4rF0J6DR3hj\nxXb+snQL7+fvAuDibhmMv7ALQzq3URA0UPFxxjcGZHFNv/a89el2Hn9/PRNnreJXb6zm4u5tufJr\nmQzv0ZYWp+HlquUVzvz1hby+fCuzlm9jx77DJCbEcWWfTG4e2pF+HVIb5fs+J70Z91/Zkx9f2p3Z\nK7bx9LxNTJy1iomzVtG3Qyoje7VjZM8zyG3bPNZdPSlRBYKZjQJ+C8QDj7v7f1ZZnwQ8BQwAdgPX\nu/uGsO4+YBxQDnzf3WdH02Z9dOhIOSu3FvPxukL++tlOPtlYRFmFk90mhe8Ny+Wb53Qgq7Vui28s\n4uIiewwje51B/o79PJe3mZmLt/DWp9tJjI/jnE6tubBrBoM6taFHZstGealiWXkFK7bsZf76QuZv\nKGTBhkL2HCwluUkcw7q35bI+mVxyVtvT5mqc5CbxjO7bntF927N2535mLd/GGyu28V+zVvNfs1bT\nOaMZ53ZJY0DH1vTPbk12m5QGFZA1vopmFg9MAkYABcACM5vp7isrVRsHFLl7rpmNBSYC15tZT2As\n0As4E3jLzLqFbWpqM2bKyivYWlzC5qKDrNt5gGUFxSwp2MOaHfspr4j8icZeZ7Zk/IWduax3Jr3b\nt2xQL7ocv9y2zfnny3tw76izWLS5iFnLt/HuZ7v4j9dXAZAQZ5yV2YI+7VP5WlYrumQ0p0ObprRr\nkdwgjjW7Ozv2HWbN9v2s2bGP/B37WbNjPys+L+bAkcjD4nLSUhjRox0Xdc9gWPe2NDtNQuBYumRE\n7nS+e1guW4sP8dbK7bz56Q7+vGgLf/w48ryl9OaJ9O3Qmq7tmtMpvRmd05vROaM5rVOa1MvPjGhe\n0UFAvruvAzCz6cBooPKH92jgZ2H+eeBhi4x2NDDd3Q8D680sP7RHFG3WmrwNhRQfKuVIWQVHyis4\nXFbBkbIK9pWUsefQEYoPllJ8qJTCA0f4fM8hthaXfPHBD9A6pQlfy0plRM92fC0rlX7ZqaQ3wBNl\ncvLi4owBHdswoGMbfnoFbN9bwqJNRSwpKGZZQTGvLt3Cs/P/9vC1xPg42rduSlbrprRplkjrlDA1\na0Krpk1IbhIfmRLi/jbfJI6khHji4sAw4ixyfiPOIssYX5S5O+UVTmm5U1ZRQVm5U1bhlFdUUFJa\nwYHDZeyvNB04XMb+kjL2lpSxY18J24pL2L73MDv3Hf7iiaIALZMT6NquBWP6ZzGoUxsGdWrTqI6V\n17bMVk25ZWgOtwzNobzC+Wz7Pj7ZVMTCjUUs2bzni4f1HdUiKYH0FkmkN08kvXkS6c2TSE1pQkpi\nAimJ8TRNjKdZYgKJCXEkxBnxccZ5uemn/HH40QRCe2BzpeUCYPCx6rh7mZkVA2mh/OMq27YP8zW1\nWWvue3EZa3bsr3ZdYnwcqSmR/5ytUxIZ2LE1HdqkkNW6KVmtU+iYlkL71Kb1Ms0l9tq1TGZU70xG\n9c4EIt+0NxUeZMPug2wuPMjmooMUFB6iYM8hNu4+SNHBI+wrKYtpn80if4u6bYsk2rVM/uLD/szU\nZHIzmpPbrjkZzZP0nj9B8XFGj8yW9MhsyU2DOwKRow4FRYdYv+sA63YdYHPhQXbuP8yufYf5bPs+\nPly7m+JDpV/Z7qp/HUV83Kk9LBlNIFT3rvAo6xyrvLpr+Kq2GWnYbDwwPizuN7PVx+hnrKUDu2Ld\niapuqt12oh5jbf3eumo3qJevYS1rVGOs5v3QqMZXWdOJX8yeyBg7RlMpmkAoADpUWs4CthyjToGZ\nJQCtgMIatq2pTQDcfTIwOYp+xpSZ5bn7wFj341Rq7GNs7OODxj/Gxj4+OLVjjOZumwVAVzPrZGaJ\nRE4Sz6xSZyZwW5i/Fpjj7h7Kx5pZkpl1AroC86NsU0RE6lCNewjhnMAEYDaRS0SfcPcVZvYgkOfu\nM4EpwLRw0riQyAc8od5zRE4WlwF3u3s5QHVt1v7wREQkWhb5Ii8ny8zGh8NbjVZjH2NjHx80/jE2\n9vHBqR2jAkFERIDoziGIiMhpQIEQBTPrYGZzzexTM1thZj8I5W3M7E0zWxN+tg7lZma/M7N8M1tq\nZv1jO4KamVmymc03syVhjD8P5Z3MbF4Y44xwEQDhQoEZYYzzzCwnlv2PlpnFm9kiM3slLDe28W0w\ns2VmttjM8kJZo3mfAphZqpk9b2arwv/JoY1ljGbWPbx2R6e9ZvbDuhqfAiE6ZcCP3L0HMAS42yKP\n5bgXeNvduwJvh2WAy4hcUdW8Fcx4AAADLklEQVSVyD0Uj9R9l4/bYeASdz8b6AuMMrMhRB5D8lAY\nYxGRx5RApceVAA+Feg3BD4BPKy03tvEBDHP3vpUuTWxM71OIPANtlrufBZxN5PVsFGN099XhtetL\n5NlwB4GXqKvxubum45yAl4k8h2k1kBnKMoHVYf5R4IZK9b+o1xAmIAX4hMjd47uAhFA+FJgd5mcD\nQ8N8Qqhnse57DePKCv+ZLgFeIXLjZKMZX+jrBiC9SlmjeZ8CLYH1VV+LxjTGSn0dCXxQl+PTHsJx\nCocO+gHzgHbuvhUg/Dz6l9qre9xHe+q5cDhlMbADeBNYC+xx96PPWqg8ji89rgQ4+riS+uw3wE+A\now/tSaNxjQ8id/y/YWYLLXKXPzSu92lnYCfwZDj097iZNaNxjfGoscCzYb5OxqdAOA5m1hx4Afih\nu+/9qqrVlNX7y7ncvdwju6pZRB5C2KO6auFngxqjmV0J7HD3hZWLq6naIMdXyXnu3p/IoYS7zezC\nr6jbEMeYAPQHHnH3fsAB/nb4pDoNcYyEc1lXAX+qqWo1ZSc8PgVClMysCZEweNrdXwzF280sM6zP\nJPLNGqJ73Ee95e57gHeInC9JtcjjSODL4/hijPblx5XUV+cBV5nZBmA6kcNGv6HxjA8Ad98Sfu4g\ncux5EI3rfVoAFLj7vLD8PJGAaExjhEigf+Lu28NynYxPgRAFMzMid2N/6u6/rrSq8iM7biNybuFo\n+a3hCoAhQPHR3b36yswyzCw1zDcFvk7kZN1cIo8jgf87xuoeV1Ivuft97p7l7jlEdsXnuPtNNJLx\nAZhZMzNrcXSeyDHo5TSi96m7bwM2m1n3UDScyJMQGs0Ygxv42+EiqKvxxfrESUOYgPOJ7IYtBRaH\n6XIix5TfBtaEn21CfSPyB4DWAsuAgbEeQxRj/BqwKIxxOfBAKO9M5PlT+UR2X5NCeXJYzg/rO8d6\nDMcx1ouBVxrb+MJYloRpBfDTUN5o3qeh332BvPBe/TPQujGNkchFHbuBVpXK6mR8ulNZREQAHTIS\nEZFAgSAiIoACQUREAgWCiIgACgQREQkUCCIiAigQREQkUCCIiAgA/x839kRtleVJ+gAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "most_common=list(ratings.movieId.value_counts().head().index)\n",
    "sns.distplot(most_common,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_id(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['id']=df['id'].apply(convert_id)\n",
    "df=df[df['id'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_genres(dfi):\n",
    "    dfi=dfi.copy()\n",
    "    \n",
    "    dfi['genres'] =dfi ['genres'].fillna('[]')\\\n",
    "    .apply(literal_eval)\\\n",
    "    .apply(lambda x: [i['name'] for i in x]\\\n",
    "          if isinstance(x, list) else [])\n",
    "\n",
    "    temp = dfi.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    temp.name = 'genre'\n",
    "    dfi = dfi.drop('genres', axis=1).join(temp)\n",
    "    return dfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate imdb rating\n",
    "def calc_imdb_rating(row,m,c):\n",
    "    v=row['vote_count']\n",
    "    r=row['vote_average']\n",
    "    return round(v/(v+m)*r+m/(v+m)*c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% popularity voting\n",
    "'''\n",
    "- v is the number of votes for the movie\n",
    "- m is the minimum votes required to be listed in the chart\n",
    "- R is the average rating of the movie\n",
    "- C is the mean vote across the whole report\n",
    "weighted_average=v/(v+m)*r+m/(v+m)*c\n",
    "'''\n",
    "def rec_popularity(df):\n",
    "    df_cur=df[df['vote_count'].notnull()][df['vote_average'].notnull()]\n",
    "    df_cur['vote_count']=df_cur['vote_count'].astype(int)\n",
    "    df_cur['vote_average']=df_cur['vote_average'].astype(float)\n",
    "    df_cur_clean=df_cur[(df_cur['vote_count'].notnull()) & (df_cur['vote_average'].notnull())]\n",
    "    m=df_cur_clean['vote_count'].quantile(0.95) #must have more votes than at least 95% of movies on the list\n",
    "    c=np.average(df_cur_clean['vote_average'],weights=df_cur_clean['vote_count'])\n",
    "    print('average score',round(c,1),'# of votes',m)\n",
    "    df_cur['weighted_rating']=df_cur.apply(lambda row:calc_imdb_rating(row,m,c),axis=1)\n",
    "    \n",
    "    df_cur_sorted=df_cur.sort_values(['weighted_rating','vote_count'],ascending=[0,0])\n",
    "    cols_to_print=['title','weighted_rating','vote_count','vote_average']\n",
    "    results=df_cur_sorted[cols_to_print].head(10)\n",
    "    return results\n",
    "\n",
    "def rec_popularity_genres(genre,df):\n",
    "    temp=df[df['genre']==genre]\n",
    "    return rec_popularity(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score 6.7 # of votes 434.0\n",
      "popular items\n",
      "\n",
      "                          title  weighted_rating  vote_count  vote_average\n",
      "314    The Shawshank Redemption              8.4        8358           8.5\n",
      "834               The Godfather              8.4        6024           8.5\n",
      "12481           The Dark Knight              8.2       12269           8.3\n",
      "2843                 Fight Club              8.2        9678           8.3\n",
      "292                Pulp Fiction              8.2        8670           8.3\n",
      "522            Schindler's List              8.2        4436           8.3\n",
      "23673                  Whiplash              8.2        4376           8.3\n",
      "15480                 Inception              8.1       14075           8.1\n",
      "351                Forrest Gump              8.1        8147           8.2\n",
      "1154    The Empire Strikes Back              8.1        5998           8.2\n"
     ]
    }
   ],
   "source": [
    "# recommendation in general\n",
    "results1=rec_popularity(df)\n",
    "print('popular items\\n')\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "df_genres=update_genres(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score 7.0 # of votes 384.0\n",
      "popular DRAMA\n",
      "\n",
      "                             title  weighted_rating  vote_count  vote_average\n",
      "314       The Shawshank Redemption              8.4        8358           8.5\n",
      "834                  The Godfather              8.4        6024           8.5\n",
      "12481              The Dark Knight              8.3       12269           8.3\n",
      "10309  Dilwale Dulhania Le Jayenge              8.3         661           9.1\n",
      "2843                    Fight Club              8.2        9678           8.3\n",
      "522               Schindler's List              8.2        4436           8.3\n",
      "23673                     Whiplash              8.2        4376           8.3\n",
      "2211             Life Is Beautiful              8.2        3643           8.3\n",
      "1178        The Godfather: Part II              8.2        3418           8.3\n",
      "22879                 Interstellar              8.1       11187           8.1\n"
     ]
    }
   ],
   "source": [
    "# recommendation for a gerne\n",
    "results2=rec_popularity_genres('Drama',df_genres)\n",
    "print('popular DRAMA\\n')\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: predicton based on description of the movie \n",
    "\n",
    "Description includes: overview and tagline\n",
    "distance metric: cosine similarity:\n",
    "    TF-IDF Vectorizer is used, calculating the Dot Product will directly give us the Cosine Similarity Score. \n",
    "    linear_kernel is used instead of cosine_similarities as it's much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create distance metric\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "def create_matrix(df,variable):\n",
    "    tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "    tfidf_matrix = tf.fit_transform(df[variable])\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    df_indexed=df.copy()\n",
    "    df_indexed['index']=df.index.tolist()\n",
    "    return cosine_sim,df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title,df,cosine_sim):\n",
    "    idx=df[df['title']==title]['index'].iloc[0]\n",
    "    results=df.copy()\n",
    "    results['score']=cosine_sim[idx].tolist()\n",
    "    \n",
    "    results=results.sort_values('score',ascending=0).head(20)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix of overview\n",
    "dfx=df.copy()\n",
    "dfx['description']=dfx['overview'].fillna('').astype(str)+' '+df['tagline'].fillna('').astype(str)\n",
    "cosine_sim,df_content=create_matrix(dfx,'description')\n",
    "del dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Toy Story \n",
      "                                               title  vote_average     score\n",
      "0                                         Toy Story           7.7  1.000000\n",
      "2997                                    Toy Story 2           7.3  0.241413\n",
      "15348                                   Toy Story 3           7.6  0.214426\n",
      "24523                                     Small Fry           6.8  0.111579\n",
      "10301                        The 40 Year Old Virgin           6.2  0.109526\n",
      "23843                   Andy Hardy's Blonde Trouble           6.3  0.102047\n",
      "8327                                      The Champ           6.8  0.101142\n",
      "43427              Andy Kaufman Plays Carnegie Hall           0.0  0.090910\n",
      "3057                                Man on the Moon           6.9  0.089616\n",
      "38476  Superstar: The Life and Times of Andy Warhol           0.0  0.087913\n",
      "42721  Andy Peters: Exclamation Mark Question Point           0.0  0.083118\n",
      "29202                                    Hot Splash           4.0  0.082576\n",
      "6435                         What's Up, Tiger Lily?           5.6  0.077975\n",
      "11606                                  Factory Girl           6.2  0.070538\n",
      "40261                                 Wabash Avenue           7.0  0.067909\n",
      "1071                          Rebel Without a Cause           7.6  0.067708\n",
      "29369                Andy Hardy's Private Secretary           5.5  0.062986\n",
      "27206                    Life Begins for Andy Hardy           6.3  0.062810\n",
      "36094                          Welcome to Happiness           4.5  0.060427\n",
      "1932                                      Condorman           5.6  0.059855\n",
      "###### The Dark Knight \n",
      "                                                    title  vote_average  \\\n",
      "12481                                    The Dark Knight           8.3   \n",
      "18252                              The Dark Knight Rises           7.6   \n",
      "150                                       Batman Forever           5.2   \n",
      "1328                                      Batman Returns           6.6   \n",
      "21194  Batman Unmasked: The Psychology of the Dark Kn...           8.0   \n",
      "15511                         Batman: Under the Red Hood           7.6   \n",
      "20232            Batman: The Dark Knight Returns, Part 2           7.9   \n",
      "41976                              The Lego Batman Movie           7.2   \n",
      "585                                               Batman           7.0   \n",
      "25267                                  Batman vs Dracula           6.5   \n",
      "18035                                   Batman: Year One           7.1   \n",
      "9230                  Batman Beyond: Return of the Joker           7.5   \n",
      "29357                         The Magnificent Dare Devil           0.0   \n",
      "40974  LEGO DC Comics Super Heroes: Batman: Be-Leaguered           6.1   \n",
      "29881                                            Accused           6.6   \n",
      "41982  Batman Beyond Darwyn Cooke's Batman 75th Anniv...           7.7   \n",
      "22021                                     The Super Cops           6.2   \n",
      "23871                          In Order of Disappearance           7.0   \n",
      "3095                        Batman: Mask of the Phantasm           7.4   \n",
      "11753                                          Slow Burn           5.5   \n",
      "\n",
      "          score  \n",
      "12481  1.000000  \n",
      "18252  0.169698  \n",
      "150    0.119121  \n",
      "1328   0.090491  \n",
      "21194  0.079468  \n",
      "15511  0.076786  \n",
      "20232  0.076700  \n",
      "41976  0.076139  \n",
      "585    0.075045  \n",
      "25267  0.072933  \n",
      "18035  0.072392  \n",
      "9230   0.070817  \n",
      "29357  0.070031  \n",
      "40974  0.069837  \n",
      "29881  0.067507  \n",
      "41982  0.066211  \n",
      "22021  0.065329  \n",
      "23871  0.063750  \n",
      "3095   0.063717  \n",
      "11753  0.059102  \n",
      "###### The Godfather \n",
      "                                   title  vote_average     score\n",
      "834                       The Godfather           8.5  1.000000\n",
      "44030  The Godfather Trilogy: 1972-1990           8.8  0.240058\n",
      "1178             The Godfather: Part II           8.3  0.226311\n",
      "31973                  Honor Thy Father           4.0  0.122551\n",
      "21614                        The Family           6.1  0.091153\n",
      "23126                        Blood Ties           6.0  0.085151\n",
      "38030          A Mother Should Be Loved           0.0  0.077303\n",
      "18322                   The Outside Man           6.8  0.073837\n",
      "11297                  Household Saints           5.0  0.067074\n",
      "10821                          Election           6.7  0.066388\n",
      "4324                               Made           6.3  0.057397\n",
      "5433                 Johnny Dangerously           6.3  0.056036\n",
      "18224                         Miss Bala           6.2  0.055807\n",
      "11992        The Cave of the Yellow Dog           7.3  0.055651\n",
      "6977                    Queen of Hearts           5.9  0.054982\n",
      "41491                     Live by Night           6.2  0.054954\n",
      "29                       Shanghai Triad           6.5  0.054413\n",
      "36569                              Plan           0.0  0.053557\n",
      "8364                               Fury           7.5  0.053223\n",
      "16955                        Easy Money           6.5  0.052875\n"
     ]
    }
   ],
   "source": [
    "# recommendation results\n",
    "for title in ['Toy Story','The Dark Knight','The Godfather']:\n",
    "    results=get_recommendations(title,df_content,cosine_sim)\n",
    "    cols_to_print=['title','vote_average','score']\n",
    "    print('######',title,'\\n',results[cols_to_print])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a user, recommend items that they may be interesting, without knowing what the user is currently looking at yet\n",
    "# 1) find top 3 rated items, 2) each item, find most similar items\n",
    "def recommend_fresh(userid,ratings,df,n=3):\n",
    "    ratings=ratings[ratings['userId']==userid].sort_values(['rating','timestamp'],ascending=[1,1]).head(3)\n",
    "    results=pd.DataFrame()\n",
    "    for title in df[df['id'].isin(ratings['movieId'])]['title'].tolist():\n",
    "        print('###### user liked',title)\n",
    "        resultsi=get_recommendations(title,df,cosine_sim)\n",
    "        results=results.append(resultsi)\n",
    "        print(resultsi['title'].tolist())\n",
    "    results=results.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### user liked Jay and Silent Bob Strike Back\n",
      "['Jay and Silent Bob Strike Back', \"Jay And Silent Bob's Super Groovy Cartoon Movie\", 'Saving Mr. Banks', 'Peacock', 'An Evening with Kevin Smith', 'Scrawl', 'Chasing Amy', 'Easy Riders, Raging Bulls', 'Double Dare', 'Sunset Boulevard', 'Hellboy: The Seeds of Creation', \"Comic-Con Episode IV: A Fan's Hope\", 'The Low Life', 'Look, Up in the Sky: The Amazing Story of Superman', 'Comic Book: The Movie', 'Born to Win', 'Danger: Diabolik', 'Sesame Street Presents Follow That Bird', 'Puckoon', 'The Movies']\n",
      "###### user liked Greed\n",
      "['Greed', 'Foolish Wives', 'Rick and Morty: State of Georgia Vs. Denver Fenton Allen', 'The Fisher King', \"Merlin's Apprentice\", 'Lucky', 'The Secret Glory', 'Zézero', 'The Visual Bible: The Gospel of John', 'Hollywood', 'The N Word', 'Captain Thunder', 'I Was an Adventuress', 'Berlin Alexanderplatz', '1812', 'City Lights', 'The Seventh Sign', 'Twin Peaks: Fire Walk with Me - The Missing Pieces', 'The Student Prince in Old Heidelberg', \"Leaves from Satan's Book\"]\n"
     ]
    }
   ],
   "source": [
    "recommend_fresh(1,ratings,df_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: predicton based on meta-data of the movie\n",
    "\n",
    "Meta-data includes: director, cast (top 4), keywords\n",
    "distance metric: CountVectorizer implements both tokenization and count of occurrence. \n",
    "\n",
    "why TfidfVectorizer?\n",
    "    several common words makes up lot of space which carry very little information about content of document.\n",
    "    If we feed these counts directly to a classifier then those frequently occurring words will shadow the real interesting terms of the document.\n",
    "  \n",
    "why CountVectorizer() instead of TF-IDF?\n",
    "    This is because you do not want to down-weight the presence of an actor/director if he or she has acted or directed in relatively more movies. It doesn't make much intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering (meta-data)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "def select_most_freq_keyword(keywords):\n",
    "    keywords['keywords']=keywords['keywords'].fillna('[]')\\\n",
    "    .apply(literal_eval)\\\n",
    "    .apply(lambda x: [i['name'] for i in x]\\\n",
    "           if isinstance(x,list) else [])\n",
    "    \n",
    "    # unroll all keywords per instance and find most frequent one\n",
    "    tmp=keywords.apply(lambda x:pd.Series(x['keywords']),axis=1).stack().reset_index(level=1,drop=True)\n",
    "    tmp_count=tmp.value_counts()\n",
    "    freq_words=tmp_count[tmp_count>1].index.tolist()\n",
    "    print('out of',len(tmp_count),'keywords',len(freq_words),'are selected')\n",
    "    \n",
    "    def filter_keywords(x,freq_words):\n",
    "        stemmer=SnowballStemmer('english')\n",
    "        words=[]\n",
    "        for i in x:\n",
    "            if i in freq_words:\n",
    "                word_cur=''.join([stemmer.stem(word.lower()) for word in word_tokenize(i)])\n",
    "                words.append(word_cur)\n",
    "        return words\n",
    "    keywords['keywords_new']=keywords['keywords'].apply(lambda x: filter_keywords(x,freq_words))\n",
    "    return keywords\n",
    "\n",
    "def select_director_cast(b):\n",
    "    #get director, two-step: 1) lower case, 2) remove blank\n",
    "    def get_director(x):\n",
    "        for i in x:\n",
    "            if i['job']=='Director':\n",
    "                return i['name'].replace(' ','').lower() \n",
    "        return ''\n",
    "    \n",
    "    b['director']=b['crew'].fillna('[]').apply(literal_eval).apply(get_director)\n",
    "    b['director']\n",
    "    \n",
    "    b['cast']=b['cast'].fillna('[]').apply(literal_eval)\\\n",
    "    .apply(lambda x: [i['name'].lower().replace(' ','') for i in x] if isinstance(x, list) else [])\n",
    "    #pick the top 4\n",
    "    b['cast']=b['cast'].apply(lambda x:x[:3] if len(x)>3 else x)\n",
    "    return b\n",
    "    \n",
    "keywords=select_most_freq_keyword(keywords)\n",
    "credit=select_director_cast(credit)\n",
    "\n",
    "df_all=df.copy()\n",
    "df_all=df_all.merge(keywords[['keywords_new','id']],on='id')\\\n",
    ".merge(credit[['id','director','cast']],on='id')\n",
    "\n",
    "df_all['vars']=df_all.apply(lambda x:' '.join(x['genres']\\\n",
    "      +x['keywords_new']\\\n",
    "      +[x['director']]*2\\\n",
    "      +x['cast']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create distance metric\n",
    "def create_matrix_count(df,variable):\n",
    "    ct = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "    tfidf_matrix = ct.fit_transform(df[variable])\n",
    "    #cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    df_indexed=df.copy()\n",
    "    df_indexed['index']=df.index.tolist()\n",
    "    return cosine_sim,df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarity matrix based on meta-data\n",
    "cosine_sim2,df_content2=create_matrix_count(df_all,'vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in ['Toy Story']:#,'The Dark Knight','The Godfather']:\n",
    "    results=get_recommendations(title,df_content2,cosine_sim)\n",
    "    print('######',title,'\\n',results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% collaborative filtering\n",
    "from surprise import Reader, Dataset, SVD, KNNBasic, evaluate,accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "reader = Reader(rating_scale=(0,5))#(rating_scale=(ratings.min(),ratings.max()))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model selection\n",
    "\n",
    "Grid Search: evaluate each model and see which one predicts the best\n",
    "- KNN method\n",
    "- SVD method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN method (use item-item based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9413419868503409\n",
      "{'sim_options': {'name': 'msd', 'user_based': False}, 'k': 40, 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "# grid search to find best score plus cross-validation\n",
    "from surprise.model_selection import GridSearchCV\n",
    "options={'name': ['cosine','pearson_baseline','msd','pearson'],'user_based': [False]}\n",
    "param_grid = {'sim_options': options,'k': [10,20,30,40],'verbose':[True]} #'sim_options': options,\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "print(results_df)\n",
    "\n",
    "# use the best estimator as the final model\n",
    "model_final = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the results\n",
    "trainset=data.build_full_trainset()\n",
    "testset=trainset.build_testset()\n",
    "\n",
    "predictions = model_final.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD method (use item-item based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9141128789617975\n",
      "{'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "0           0.947298          0.949168          0.943639        0.946702   \n",
      "1           0.953221          0.955340          0.948866        0.952475   \n",
      "2           0.926176          0.928019          0.923399        0.925864   \n",
      "3           0.933623          0.935773          0.929978        0.933125   \n",
      "4           0.930225          0.932258          0.927709        0.930064   \n",
      "5           0.937379          0.939623          0.933884        0.936962   \n",
      "6           0.914317          0.915863          0.912159        0.914113   \n",
      "7           0.922820          0.924591          0.919564        0.922325   \n",
      "8           0.947394          0.949329          0.943939        0.946887   \n",
      "9           0.953357          0.955423          0.949037        0.952605   \n",
      "10          0.926269          0.928074          0.923464        0.925936   \n",
      "11          0.933588          0.935777          0.929984        0.933116   \n",
      "12          0.930261          0.932345          0.927594        0.930067   \n",
      "13          0.937355          0.939650          0.933933        0.936979   \n",
      "14          0.914450          0.915957          0.912145        0.914184   \n",
      "15          0.922885          0.924611          0.919518        0.922338   \n",
      "16          0.948003          0.949980          0.944397        0.947460   \n",
      "17          0.953580          0.955566          0.948878        0.952675   \n",
      "18          0.926390          0.928258          0.923632        0.926093   \n",
      "19          0.933712          0.935927          0.930130        0.933257   \n",
      "20          0.930330          0.932705          0.927992        0.930342   \n",
      "21          0.937456          0.939795          0.934015        0.937088   \n",
      "22          0.914560          0.916063          0.912341        0.914321   \n",
      "23          0.922938          0.924748          0.919630        0.922439   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "0        0.002297              19         0.742400         0.746240   \n",
      "1        0.002695              22         0.748556         0.752642   \n",
      "2        0.001899               7         0.720946         0.724273   \n",
      "3        0.002392              14         0.728797         0.732465   \n",
      "4        0.001860              10         0.725283         0.728653   \n",
      "5        0.002362              16         0.732654         0.736502   \n",
      "6        0.001519               1         0.709874         0.712726   \n",
      "7        0.002082               4         0.718730         0.721814   \n",
      "8        0.002230              20         0.742438         0.746267   \n",
      "9        0.002661              23         0.748702         0.752779   \n",
      "10       0.001897               8         0.721003         0.724286   \n",
      "11       0.002388              13         0.728770         0.732485   \n",
      "12       0.001944              11         0.725262         0.728773   \n",
      "13       0.002349              17         0.732577         0.736463   \n",
      "14       0.001567               2         0.709967         0.712843   \n",
      "15       0.002115               5         0.718763         0.721838   \n",
      "16       0.002311              21         0.742815         0.746766   \n",
      "17       0.002805              24         0.748932         0.752885   \n",
      "18       0.001900               9         0.721176         0.724395   \n",
      "19       0.002388              15         0.728878         0.732620   \n",
      "20       0.001924              12         0.725452         0.729080   \n",
      "21       0.002374              18         0.732723         0.736691   \n",
      "22       0.001529               3         0.710099         0.712934   \n",
      "23       0.002119               6         0.718863         0.721919   \n",
      "\n",
      "    split2_test_mae  mean_test_mae      ...        rank_test_mae  \\\n",
      "0          0.738358       0.742333      ...                   19   \n",
      "1          0.744346       0.748515      ...                   22   \n",
      "2          0.716777       0.720665      ...                    7   \n",
      "3          0.724351       0.728538      ...                   14   \n",
      "4          0.721300       0.725079      ...                   10   \n",
      "5          0.728457       0.732538      ...                   17   \n",
      "6          0.706452       0.709684      ...                    1   \n",
      "7          0.714682       0.718409      ...                    4   \n",
      "8          0.738508       0.742405      ...                   20   \n",
      "9          0.744495       0.748659      ...                   23   \n",
      "10         0.716847       0.720712      ...                    8   \n",
      "11         0.724334       0.728530      ...                   13   \n",
      "12         0.721269       0.725102      ...                   11   \n",
      "13         0.728555       0.732532      ...                   16   \n",
      "14         0.706428       0.709746      ...                    2   \n",
      "15         0.714658       0.718420      ...                    5   \n",
      "16         0.738743       0.742775      ...                   21   \n",
      "17         0.744471       0.748763      ...                   24   \n",
      "18         0.716918       0.720830      ...                    9   \n",
      "19         0.724477       0.728658      ...                   15   \n",
      "20         0.721576       0.725369      ...                   12   \n",
      "21         0.728569       0.732661      ...                   18   \n",
      "22         0.706531       0.709855      ...                    3   \n",
      "23         0.714739       0.718507      ...                    6   \n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "0        0.427066      0.009280        0.392090       0.037002   \n",
      "1        0.402416      0.000471        0.384094       0.030052   \n",
      "2        0.403081      0.004189        0.382428       0.025962   \n",
      "3        0.405414      0.007841        0.386093       0.034274   \n",
      "4        0.805831      0.006940        0.379097       0.031921   \n",
      "5        0.797504      0.005097        0.378098       0.031332   \n",
      "6        0.803833      0.000471        0.383427       0.032336   \n",
      "7        0.812160      0.007582        0.387093       0.035758   \n",
      "8        0.504686      0.007252        0.392755       0.034887   \n",
      "9        0.490361      0.003298        0.377432       0.035627   \n",
      "10       0.488695      0.003557        0.379764       0.034688   \n",
      "11       0.495358      0.001246        0.383760       0.030608   \n",
      "12       0.982720      0.002866        0.387759       0.026679   \n",
      "13       0.991715      0.008725        0.377765       0.032011   \n",
      "14       0.994713      0.013465        0.390092       0.035646   \n",
      "15       0.988717      0.011257        0.379430       0.032988   \n",
      "16       0.776515      0.012186        0.385760       0.042736   \n",
      "17       0.778849      0.012651        0.392089       0.034852   \n",
      "18       0.782179      0.016490        0.383762       0.033958   \n",
      "19       0.769521      0.000816        0.383428       0.033805   \n",
      "20       1.560361      0.009666        0.397419       0.028877   \n",
      "21       1.544705      0.018068        0.388758       0.029010   \n",
      "22       1.548702      0.017431        0.387758       0.040578   \n",
      "23       1.572686      0.016926        0.387092       0.038553   \n",
      "\n",
      "                                               params param_n_factors  \\\n",
      "0   {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.0...              10   \n",
      "1   {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.0...              10   \n",
      "2   {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.0...              10   \n",
      "3   {'n_factors': 10, 'n_epochs': 5, 'lr_all': 0.0...              10   \n",
      "4   {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0....              10   \n",
      "5   {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0....              10   \n",
      "6   {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0....              10   \n",
      "7   {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0....              10   \n",
      "8   {'n_factors': 20, 'n_epochs': 5, 'lr_all': 0.0...              20   \n",
      "9   {'n_factors': 20, 'n_epochs': 5, 'lr_all': 0.0...              20   \n",
      "10  {'n_factors': 20, 'n_epochs': 5, 'lr_all': 0.0...              20   \n",
      "11  {'n_factors': 20, 'n_epochs': 5, 'lr_all': 0.0...              20   \n",
      "12  {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0....              20   \n",
      "13  {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0....              20   \n",
      "14  {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0....              20   \n",
      "15  {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0....              20   \n",
      "16  {'n_factors': 50, 'n_epochs': 5, 'lr_all': 0.0...              50   \n",
      "17  {'n_factors': 50, 'n_epochs': 5, 'lr_all': 0.0...              50   \n",
      "18  {'n_factors': 50, 'n_epochs': 5, 'lr_all': 0.0...              50   \n",
      "19  {'n_factors': 50, 'n_epochs': 5, 'lr_all': 0.0...              50   \n",
      "20  {'n_factors': 50, 'n_epochs': 10, 'lr_all': 0....              50   \n",
      "21  {'n_factors': 50, 'n_epochs': 10, 'lr_all': 0....              50   \n",
      "22  {'n_factors': 50, 'n_epochs': 10, 'lr_all': 0....              50   \n",
      "23  {'n_factors': 50, 'n_epochs': 10, 'lr_all': 0....              50   \n",
      "\n",
      "    param_n_epochs  param_lr_all  param_reg_all  \n",
      "0                5         0.002            0.4  \n",
      "1                5         0.002            0.6  \n",
      "2                5         0.005            0.4  \n",
      "3                5         0.005            0.6  \n",
      "4               10         0.002            0.4  \n",
      "5               10         0.002            0.6  \n",
      "6               10         0.005            0.4  \n",
      "7               10         0.005            0.6  \n",
      "8                5         0.002            0.4  \n",
      "9                5         0.002            0.6  \n",
      "10               5         0.005            0.4  \n",
      "11               5         0.005            0.6  \n",
      "12              10         0.002            0.4  \n",
      "13              10         0.002            0.6  \n",
      "14              10         0.005            0.4  \n",
      "15              10         0.005            0.6  \n",
      "16               5         0.002            0.4  \n",
      "17               5         0.002            0.6  \n",
      "18               5         0.005            0.4  \n",
      "19               5         0.005            0.6  \n",
      "20              10         0.002            0.4  \n",
      "21              10         0.002            0.6  \n",
      "22              10         0.005            0.4  \n",
      "23              10         0.005            0.6  \n",
      "\n",
      "[24 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# grid search to find best score plus cross-validation\n",
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_factors':[10,20,50],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(T)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "results_df_svd = pd.DataFrame.from_dict(gs.cv_results)\n",
    "print(results_df_svd)\n",
    "\n",
    "# use the best estimator as the final model\n",
    "model_final_svd = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8837\n",
      "MAE:  0.6858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.685782838755112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the results\n",
    "trainset=data.build_full_trainset()\n",
    "testset=trainset.build_testset()\n",
    "\n",
    "predictions = model_final_svd.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if only use one algorithm, and cross validate this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9964\n",
      "MAE:  0.7689\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.3760\n",
      "MAE:  0.2630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2630012628207597"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single method, cross_validation to evaluate score\n",
    "from surprise.model_selection import validation\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "model=KNNBasic(sim_options={'name':'pearson_baseline'})\n",
    "#evaluate(model, data, measures=['RMSE', 'MAE'])\n",
    "validation.cross_validate(model, data, measures=[u'rmse', u'mae'], \n",
    "                          cv=5, return_train_measures=False,\n",
    "                          n_jobs=1, verbose=False)\n",
    "\n",
    "def split_data(data):\n",
    "    from surprise.model_selection import train_test_split        \n",
    "    # sample random trainset and testset\n",
    "    # test set is made of 25% of the ratings.\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "    return trainset, testset\n",
    "\n",
    "def whole_data(data):\n",
    "    trainset=data.build_full_trainset()\n",
    "    testset=trainset.build_testset()\n",
    "    return trainset, testset\n",
    "\n",
    "# split data\n",
    "trainset, testset=split_data(data)\n",
    "predictions = model.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "# whole data\n",
    "trainset, testset=whole_data(data)\n",
    "predictions = model.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data before launching the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0124\n",
      "MAE:  0.7796\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0138\n",
      "MAE:  0.7828\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0113\n",
      "MAE:  0.7804\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0125\n",
      "Mean MAE : 0.7809\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'rmse': [1.012405981903362,\n",
       "                             1.013807542269437,\n",
       "                             1.0112931810851185],\n",
       "                            'mae': [0.7796309392309435,\n",
       "                             0.7827605104993606,\n",
       "                             0.7804190641265616]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split(n_folds=3)\n",
    "model=KNNBasic(sim_options={'name':'pearson_baseline'})\n",
    "evaluate(model, data, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give rating to the top n picks\n",
    "def rate_topn(uid,dfx,model):\n",
    "    for ind,row in dfx.iterrows():\n",
    "        score=model.predict(uid,int(row['id'])).est\n",
    "        dfx.set_value(ind,'cb_score',score)\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test consistency\n",
    "predictions=model_final.test(trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid=1, iid=1061, r_ui=3.0, est=2.578009364916735, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1129, r_ui=2.0, est=2.4733788220804764, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1172, r_ui=4.0, est=2.6665340725786093, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1263, r_ui=2.0, est=2.429273260273908, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1287, r_ui=2.0, est=2.5571401906891844, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1293, r_ui=2.0, est=2.442047246798517, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1339, r_ui=3.5, est=2.587278887904752, details={'actual_k': 20, 'was_impossible': False}), Prediction(uid=1, iid=1343, r_ui=2.0, est=2.534092565720418, details={'actual_k': 20, 'was_impossible': False})]\n",
      "user: 1          item: 1061       r_ui = None   est = 2.58   {'actual_k': 20, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(predictions[2]) # print the second indexed user & item, their results\n",
    "print(model_final.predict(1,1061))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf will use average ratings of the training set if (movie) or (user) does not exist in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_method(title,userid,df,cosine_sim,cf_model):\n",
    "    # step 1: recommend similar items to user's current selection\n",
    "    results=get_recommendations(title,df,cosine_sim)\n",
    "    # step 2: suggest top picks based on assumed rating of the user\n",
    "    results=rate_topn(userid,results,cf_model)\n",
    "    # step 3: output the results\n",
    "    results=results.sort_values(['cb_score','score'],ascending=[0,0])\\\n",
    "    .rename(columns={'cb_score':'predicted_rating','score':'similarity'})\\\n",
    "    [['title','vote_average','predicted_rating','similarity']]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>Batman Returns</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.755942</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.155449</td>\n",
       "      <td>0.070592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.924325</td>\n",
       "      <td>0.090491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25267</th>\n",
       "      <td>Batman vs Dracula</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.151451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15511</th>\n",
       "      <td>Batman: Under the Red Hood</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.129254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21194</th>\n",
       "      <td>Batman Unmasked: The Psychology of the Dark Kn...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.126443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18252</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.122640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41982</th>\n",
       "      <td>Batman Beyond Darwyn Cooke's Batman 75th Anniv...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.120516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41976</th>\n",
       "      <td>The Lego Batman Movie</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.114206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40974</th>\n",
       "      <td>LEGO DC Comics Super Heroes: Batman: Be-Leaguered</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.111119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40946</th>\n",
       "      <td>Batman: Return of the Caped Crusaders</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.104698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20232</th>\n",
       "      <td>Batman: The Dark Knight Returns, Part 2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.104067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Batman: Mask of the Phantasm</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.097332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29536</th>\n",
       "      <td>Batman Unlimited: Animal Instincts</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.085835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41981</th>\n",
       "      <td>DC Showcase: Catwoman</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.084223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22021</th>\n",
       "      <td>The Super Cops</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.084129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>Batman Beyond: Return of the Joker</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.079828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32119</th>\n",
       "      <td>Batman Unlimited: Monster Mayhem</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.079463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43779</th>\n",
       "      <td>Batman &amp; Bill</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.069585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35983</th>\n",
       "      <td>Batman: Bad Blood</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>0.067896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  vote_average  \\\n",
       "1328                                      Batman Returns           6.6   \n",
       "150                                       Batman Forever           5.2   \n",
       "12481                                    The Dark Knight           8.3   \n",
       "25267                                  Batman vs Dracula           6.5   \n",
       "15511                         Batman: Under the Red Hood           7.6   \n",
       "21194  Batman Unmasked: The Psychology of the Dark Kn...           8.0   \n",
       "18252                              The Dark Knight Rises           7.6   \n",
       "41982  Batman Beyond Darwyn Cooke's Batman 75th Anniv...           7.7   \n",
       "41976                              The Lego Batman Movie           7.2   \n",
       "40974  LEGO DC Comics Super Heroes: Batman: Be-Leaguered           6.1   \n",
       "40946              Batman: Return of the Caped Crusaders           7.2   \n",
       "20232            Batman: The Dark Knight Returns, Part 2           7.9   \n",
       "3095                        Batman: Mask of the Phantasm           7.4   \n",
       "29536                 Batman Unlimited: Animal Instincts           5.5   \n",
       "41981                              DC Showcase: Catwoman           6.5   \n",
       "22021                                     The Super Cops           6.2   \n",
       "9230                  Batman Beyond: Return of the Joker           7.5   \n",
       "32119                   Batman Unlimited: Monster Mayhem           6.0   \n",
       "43779                                      Batman & Bill           7.7   \n",
       "35983                                  Batman: Bad Blood           6.8   \n",
       "\n",
       "       predicted_rating  similarity  \n",
       "1328           4.755942    1.000000  \n",
       "150            4.155449    0.070592  \n",
       "12481          3.924325    0.090491  \n",
       "25267          3.543608    0.151451  \n",
       "15511          3.543608    0.129254  \n",
       "21194          3.543608    0.126443  \n",
       "18252          3.543608    0.122640  \n",
       "41982          3.543608    0.120516  \n",
       "41976          3.543608    0.114206  \n",
       "40974          3.543608    0.111119  \n",
       "40946          3.543608    0.104698  \n",
       "20232          3.543608    0.104067  \n",
       "3095           3.543608    0.097332  \n",
       "29536          3.543608    0.085835  \n",
       "41981          3.543608    0.084223  \n",
       "22021          3.543608    0.084129  \n",
       "9230           3.543608    0.079828  \n",
       "32119          3.543608    0.079463  \n",
       "43779          3.543608    0.069585  \n",
       "35983          3.543608    0.067896  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_method('Batman Returns',4,df_content,cosine_sim,model_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_ontrain(data):\n",
    "    from surprise.model_selection import KFold\n",
    "    kf = KFold(n_splits=3)\n",
    "    algo = SVD()\n",
    "    for trainset, testset in kf.split(data):\n",
    "        # train and test algorithm.\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        # Compute and print Root Mean Squared Error\n",
    "        print(accuracy.rmse(predictions, verbose=True))\n",
    "        print(accuracy.mae(predictions, verbose=True))\n",
    "\n",
    "k_fold_ontrain(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
